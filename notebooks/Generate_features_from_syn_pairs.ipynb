{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import re\n",
    "import collections\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gzip\n",
    "import datetime\n",
    "import pickle\n",
    "import itertools\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "from nltk.util import ngrams\n",
    "from wordcloud import WordCloud\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from collections import Counter\n",
    "from bisect import bisect_left\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22:29:13.013116\n"
     ]
    }
   ],
   "source": [
    "# Debug\n",
    "print(datetime.datetime.now().time())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create featureset\n",
    "Load the dataset with the generated synthetic candidate queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "syn_candidate_queries.to_pickle('/Users/rwkoops/PycharmProjects/IR_project/IR_project_02/created_sample/syn_candidate_queries_5m.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "syn_candidate_queries = pd.read_pickle('/Users/rwkoops/PycharmProjects/IR_project/IR_project_02/created_sample/syn_candidate_queries_5m.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create N-gram & NER features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/rwkoops/PycharmProjects/IR_project/IR_project_02/created_sample/hist_suffixes.pickle_1m', 'rb') as f:\n",
    "    suffixes = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create N-gram features based on the \"Query_clean\"-column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_dict = collections.Counter(suffixes)\n",
    "\n",
    "def ngram_freq_per_n(candidate, historical_dict, n):\n",
    "    words = candidate.split()\n",
    "    ngram_n = 0\n",
    "    ngrams_i = ngrams(words, n)\n",
    "    \n",
    "    for word in ngrams_i:\n",
    "        freq_g = historical_dict[\" \".join(word)]\n",
    "        ngram_n += freq_g\n",
    "        \n",
    "    return ngram_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_max = 6\n",
    "\n",
    "for i in range(1, ngram_max + 1):\n",
    "    ngram_name = 'ngram_' + str(i)\n",
    "    syn_candidate_queries[ngram_name] = syn_candidate_queries[syn_candidate_queries.notnull()]['Query_clean'].map(lambda candidate_row: ngram_freq_per_n(candidate_row, historical_dict, i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create NER Features based on the \"Synthetic_query\"-column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ner_contains_and_count_norm(candidate): \n",
    "    entities = nlp(str(candidate))\n",
    "    contains = 0\n",
    "    ner_norm = 0\n",
    "    \n",
    "    if len(entities) > 0:\n",
    "        contains = 1\n",
    "        ner_norm = len(entities) / len(candidate)\n",
    "    \n",
    "    return [contains, ner_norm]\n",
    "\n",
    "syn_candidate_queries['has_ne'], syn_candidate_queries['ne_norm'] = zip(*syn_candidate_queries[syn_candidate_queries.notnull()]['Synthetic_query'].map(lambda candidate_row: ner_contains_and_count_norm(candidate_row)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create 'Other'-features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_other_features(prefix, suffix, candidate, historical_logs):\n",
    "    # Boolean indicating whether the prefix ends with a space\n",
    "    bool_space = prefix.endswith(\" \")\n",
    "    \n",
    "    # The frequency of the candidate in the historical logs\n",
    "    frequency = historical_logs[candidate]\n",
    "    \n",
    "    # Prefix, suffix and total length in characters\n",
    "    prefixlen_char = len(prefix)\n",
    "    suffixlen_char = len(suffix)\n",
    "    totallen_char = len(candidate)\n",
    "    \n",
    "    # Prefix, suffix and total length in words\n",
    "    prefixlen_word = len(prefix.split())\n",
    "    suffixlen_word = len(suffix.split())\n",
    "    totallen_word = len(candidate.split())\n",
    "    \n",
    "    return [frequency, \n",
    "            prefixlen_char, suffixlen_char, totallen_char,\n",
    "            prefixlen_word, suffixlen_word, totallen_word,\n",
    "            bool_space * 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syn_candidate_queries['candid_freq'], syn_candidate_queries['prefixlen_char'], syn_candidate_queries['suffixlen_char'], syn_candidate_queries['totallen_char'], syn_candidate_queries['prefixlen_word'], syn_candidate_queries['suffixlen_word'], syn_candidate_queries['totallen_word'] = zip(*queries.apply(lambda query_row: get_other_features(query_row.Prefix, query_row.Suffix, query_row.Synthetic_query, historical_dict), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug\n",
    "print(datetime.datetime.now().time())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
